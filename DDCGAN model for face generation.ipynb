{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tridibraj/dcgan-model-for-face-generation-need-improvement?scriptVersionId=202680434\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Create a small Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport shutil\n\n# Constants\nSOURCE_DIR = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba'\nTARGET_DIR = '/kaggle/working/selected_images'\nNUM_IMAGES = 20000\n\n# Ensure the target directory exists\nos.makedirs(TARGET_DIR, exist_ok=True)\n\n# List all image files in the source directory\nall_image_files = [f for f in os.listdir(SOURCE_DIR) if f.endswith(('.jpg', '.png'))]\n\n# Randomly select a subset of images\nselected_files = random.sample(all_image_files, NUM_IMAGES)\n\n# Copy selected images to the target directory\nfor filename in selected_files:\n    src_path = os.path.join(SOURCE_DIR, filename)\n    dst_path = os.path.join(TARGET_DIR, filename)\n    shutil.copyfile(src_path, dst_path)\n\nprint(f\"Copied {NUM_IMAGES} images to {TARGET_DIR}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:10:02.131654Z","iopub.execute_input":"2024-10-22T15:10:02.132284Z","iopub.status.idle":"2024-10-22T15:15:30.892317Z","shell.execute_reply.started":"2024-10-22T15:10:02.132253Z","shell.execute_reply":"2024-10-22T15:15:30.891415Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Delete Files if Needed","metadata":{}},{"cell_type":"code","source":"# import os\n# import shutil\n\n# # Path to the kaggle working directory\n# WORKING_DIR = '/kaggle/working'\n\n# # List all items in the working directory\n# items = os.listdir(WORKING_DIR)\n\n# # Iterate over all items\n# for item in items:\n#     item_path = os.path.join(WORKING_DIR, item)\n#     # Check if the item is a directory\n#     if os.path.isdir(item_path):\n#         print(f\"Deleting folder: {item_path}\")\n#         shutil.rmtree(item_path)  # Delete the folder and its contents\n\n# print(\"All folders in the kaggle working directory have been deleted.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T09:34:07.263374Z","iopub.execute_input":"2024-07-18T09:34:07.264197Z","iopub.status.idle":"2024-07-18T09:34:07.269556Z","shell.execute_reply.started":"2024-07-18T09:34:07.264162Z","shell.execute_reply":"2024-07-18T09:34:07.268283Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torchvision.utils import save_image, make_grid\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-07-18T09:34:07.271033Z","iopub.execute_input":"2024-07-18T09:34:07.271455Z","iopub.status.idle":"2024-07-18T09:34:07.285354Z","shell.execute_reply.started":"2024-07-18T09:34:07.271421Z","shell.execute_reply":"2024-07-18T09:34:07.283891Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"\n\n# Constants\nDATA_DIR = '/kaggle/working/selected_images'  # Use the kaggle/working directory\nIMAGE_SIZE = 64\nBATCH_SIZE = 128\nLATENT_DIM = 100\nEPOCHS = 300\nSAVE_INTERVAL = 3  # Interval to save and show images\n\n# Create directory to save images\nos.makedirs(\"images\", exist_ok=True)\n\n# Transformations for the dataset\ntransform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\n# Custom dataset to load images from a list of file paths\nclass ImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.file_list = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(('.jpg', '.png'))]\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        image = Image.open(img_path)\n        if self.transform:\n            image = self.transform(image)\n        return image\n\nprint(\"Loading dataset...\")\n# Create the dataset and data loader for the images\ndataset = ImageDataset(DATA_DIR, transform=transform)\ndata_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\nprint(\"Dataset loaded and data loader created.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-18T09:34:07.288607Z","iopub.execute_input":"2024-07-18T09:34:07.289096Z","iopub.status.idle":"2024-07-18T09:34:07.458835Z","shell.execute_reply.started":"2024-07-18T09:34:07.289051Z","shell.execute_reply":"2024-07-18T09:34:07.457664Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Architecture","metadata":{}},{"cell_type":"code","source":"\n# Define the Generator\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(LATENT_DIM, 128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256, 0.8),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512, 0.8),\n            nn.ReLU(),\n            nn.Linear(512, 1024),\n            nn.BatchNorm1d(1024, 0.8),\n            nn.ReLU(),\n            nn.Linear(1024, IMAGE_SIZE * IMAGE_SIZE * 3),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        img = self.model(z)\n        img = img.view(img.size(0), 3, IMAGE_SIZE, IMAGE_SIZE)\n        return img\n\n# Define the Discriminator\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(IMAGE_SIZE * IMAGE_SIZE * 3, 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1)\n        validity = self.model(img_flat)\n        return validity\n\n# Initialize the models\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n# Loss and optimizers\nadversarial_loss = nn.BCELoss()\noptimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T09:34:07.460392Z","iopub.execute_input":"2024-07-18T09:34:07.460832Z","iopub.status.idle":"2024-07-18T09:34:07.740575Z","shell.execute_reply.started":"2024-07-18T09:34:07.46079Z","shell.execute_reply":"2024-07-18T09:34:07.739577Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Function to display images\ndef display_images(epoch):\n    z = torch.randn(25, LATENT_DIM)\n    gen_imgs = generator(z)\n    gen_imgs = gen_imgs.view(25, 3, IMAGE_SIZE, IMAGE_SIZE)\n    gen_imgs = gen_imgs * 0.5 + 0.5  # Denormalize\n    grid = make_grid(gen_imgs, nrow=5)\n    np_grid = grid.numpy()\n    plt.figure(figsize=(10, 10))\n    plt.imshow(np.transpose(np_grid, (1, 2, 0)))\n    plt.title(f\"Epoch {epoch}\")\n    plt.show()\n\n# Training the GAN\nprint(\"Starting training...\")\nfor epoch in range(EPOCHS):\n    for i, imgs in enumerate(data_loader):\n        \n        # Ground truths\n        valid = torch.ones(imgs.size(0), 1, requires_grad=False)\n        fake = torch.zeros(imgs.size(0), 1, requires_grad=False)\n        \n        # Configure input\n        real_imgs = imgs.type(torch.FloatTensor)\n        \n        # Train Generator\n        optimizer_G.zero_grad()\n        z = torch.randn(imgs.shape[0], LATENT_DIM)\n        gen_imgs = generator(z)\n        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n        g_loss.backward()\n        optimizer_G.step()\n        \n        # Train Discriminator\n        optimizer_D.zero_grad()\n        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n        d_loss = (real_loss + fake_loss) / 2\n        d_loss.backward()\n        optimizer_D.step()\n        \n        # Print progress\n        if i % 500 == 0:\n            print(f\"[Epoch {epoch}/{EPOCHS}] [Batch {i}/{len(data_loader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n\n    # Save and show generated samples after every 3 epochs\n    if epoch % SAVE_INTERVAL == 0:\n        print(f\"Displaying and saving images for epoch {epoch}...\")\n        display_images(epoch)\n        save_image(gen_imgs.data[:25], f\"images/epoch_{epoch}.png\", nrow=5, normalize=True)\n\n# Save the generator model\nprint(\"Training complete. Saving the generator model...\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T09:34:07.742208Z","iopub.execute_input":"2024-07-18T09:34:07.743188Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save the Model","metadata":{}},{"cell_type":"code","source":"# Initialize the Generator model\ngenerator = Generator()\n\n# Save the generator model to the Kaggle working directory\ntorch.save(generator.state_dict(), \"/kaggle/working/generator.pth\")\nprint(\"Model saved to /kaggle/working/generator.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndef find_file(root_dir, filename):\n    for root, dirs, files in os.walk(root_dir):\n        if filename in files:\n            return os.path.join(root, filename)\n    return None\n\n# Define the root directory and the filename\nroot_dir = '/kaggle/working'\nfilename = 'generator.pth'\n\n# Find the file and print the location\nfile_path = find_file(root_dir, filename)\n\nif file_path:\n    print(f\"File '{filename}' found at: {file_path}\")\nelse:\n    print(f\"File '{filename}' not found in {root_dir}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modified architecture ( takes too much time to train)","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torchvision.utils import save_image, make_grid\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:09:08.352148Z","iopub.execute_input":"2024-10-22T15:09:08.353005Z","iopub.status.idle":"2024-10-22T15:09:13.000803Z","shell.execute_reply.started":"2024-10-22T15:09:08.352969Z","shell.execute_reply":"2024-10-22T15:09:13.000017Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Constants\nDATA_DIR = '/kaggle/working/selected_images'  # Use the kaggle/working directory\nIMAGE_SIZE = 64\nBATCH_SIZE = 128\nLATENT_DIM = 100\nEPOCHS = 3\nSAVE_INTERVAL = 3  # Interval to save and show images\n\n# Create directory to save images\nos.makedirs(\"images\", exist_ok=True)\n\n# Transformations for the dataset\ntransform = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\n# Custom dataset to load images from a list of file paths\nclass ImageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.file_list = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith(('.jpg', '.png'))]\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        image = Image.open(img_path)\n        if self.transform:\n            image = self.transform(image)\n        return image\n\nprint(\"Loading dataset...\")\n# Create the dataset and data loader for the images\ndataset = ImageDataset(DATA_DIR, transform=transform)\ndata_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\nprint(\"Dataset loaded and data loader created.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:22:28.918287Z","iopub.execute_input":"2024-10-22T15:22:28.919021Z","iopub.status.idle":"2024-10-22T15:22:29.059965Z","shell.execute_reply.started":"2024-10-22T15:22:28.918988Z","shell.execute_reply":"2024-10-22T15:22:29.059074Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the Generator (DCGAN)\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.init_size = IMAGE_SIZE // 4\n        self.l1 = nn.Sequential(nn.Linear(LATENT_DIM, 128 * self.init_size ** 2))\n        self.conv_blocks = nn.Sequential(\n            nn.BatchNorm2d(128),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n            nn.BatchNorm2d(128, 0.8),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n            nn.BatchNorm2d(64, 0.8),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, z):\n        out = self.l1(z)\n        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n        img = self.conv_blocks(out)\n        return img\n\n# Define the Discriminator (DCGAN)\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 16, 3, 2, 1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout2d(0.25),\n            nn.Conv2d(16, 32, 3, 2, 1),\n            nn.BatchNorm2d(32, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout2d(0.25),\n            nn.Conv2d(32, 64, 3, 2, 1),\n            nn.BatchNorm2d(64, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout2d(0.25),\n            nn.Conv2d(64, 128, 3, 2, 1),\n            nn.BatchNorm2d(128, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout2d(0.25),\n            nn.Flatten(),\n            nn.Linear(128 * 4 * 4, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, img):\n        validity = self.model(img)\n        return validity\n\n# Initialize the models\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n# Loss and optimizers\nadversarial_loss = nn.BCELoss()\noptimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n# Function to display images\ndef display_images(epoch):\n    z = torch.randn(25, LATENT_DIM)\n    gen_imgs = generator(z)\n    gen_imgs = gen_imgs * 0.5 + 0.5  # Denormalize\n    grid = make_grid(gen_imgs, nrow=5)\n    np_grid = grid.numpy()\n    plt.figure(figsize=(10, 10))\n    plt.imshow(np.transpose(np_grid, (1, 2, 0)))\n    plt.title(f\"Epoch {epoch}\")\n    plt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:22:56.36174Z","iopub.execute_input":"2024-10-22T15:22:56.362554Z","iopub.status.idle":"2024-10-22T15:22:56.419047Z","shell.execute_reply.started":"2024-10-22T15:22:56.362521Z","shell.execute_reply":"2024-10-22T15:22:56.418261Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training the GAN\nprint(\"Starting training...\")\nfor epoch in range(EPOCHS):\n    for i, imgs in enumerate(data_loader):\n        \n        # Ground truths\n        valid = torch.ones(imgs.size(0), 1, requires_grad=False)\n        fake = torch.zeros(imgs.size(0), 1, requires_grad=False)\n        \n        # Configure input\n        real_imgs = imgs.type(torch.FloatTensor)\n        \n        # Train Generator\n        optimizer_G.zero_grad()\n        z = torch.randn(imgs.shape[0], LATENT_DIM)\n        gen_imgs = generator(z)\n        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n        g_loss.backward()\n        optimizer_G.step()\n        \n        # Train Discriminator\n        optimizer_D.zero_grad()\n        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n        d_loss = (real_loss + fake_loss) / 2\n        d_loss.backward()\n        optimizer_D.step()\n        \n        # Print progress\n        if i % 500 == 0:\n            print(f\"[Epoch {epoch}/{EPOCHS}] [Batch {i}/{len(data_loader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n\n    # Save and show generated samples after every 3 epochs\n    if epoch % SAVE_INTERVAL == 0:\n        print(f\"Displaying and saving images for epoch {epoch}...\")\n        display_images(epoch)\n        save_image(gen_imgs.data[:25], f\"images/epoch_{epoch}.png\", nrow=5, normalize=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-22T15:22:59.681432Z","iopub.execute_input":"2024-10-22T15:22:59.681784Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the generator model\nprint(\"Training complete. Saving the generator model...\")\ntorch.save(generator.state_dict(), \"generator.pth\")\nprint(\"Model saved.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}